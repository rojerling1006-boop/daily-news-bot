import requests
from bs4 import BeautifulSoup
from deep_translator import GoogleTranslator
import time
import os
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from datetime import datetime

# --- è¨­å®šå€ (ç²¾é¸ 16 å€‹æ–°èä¾†æº) ---
news_sources = [
    { "name": "AP News (ç¾è¯ç¤¾)", "url": "https://apnews.com/hub/world-news", "tag": "h3", "root": "https://apnews.com" },
    { "name": "CNN", "url": "https://edition.cnn.com/world", "tag": "span", "root": "https://edition.cnn.com" },
    { "name": "BBC News", "url": "https://www.bbc.com/news", "tag": "h2", "root": "https://www.bbc.com" },
    { "name": "The Guardian (è¡›å ±)", "url": "https://www.theguardian.com/international", "tag": "h3", "root": "" },
    { "name": "NPR (ç¾åœ‹å…¬å…±å»£æ’­)", "url": "https://www.npr.org/sections/news/", "tag": "h2", "root": "" },
    { "name": "Al Jazeera (åŠå³¶é›»è¦–å°)", "url": "https://www.aljazeera.com/news/", "tag": "h3", "root": "https://www.aljazeera.com" },
    { "name": "Nature (ç§‘å­¸æœŸåˆŠ)", "url": "https://www.nature.com/news", "tag": "h3", "root": "" },
    { "name": "The New York Times (ç´ç´„æ™‚å ±)", "url": "https://www.nytimes.com/section/world", "tag": "h3", "root": "https://www.nytimes.com" },
    { "name": "The Washington Post (è¯ç››é “éƒµå ±)", "url": "https://www.washingtonpost.com/world", "tag": "h2", "root": "" },
    { "name": "Nikkei Asia (æ—¥ç¶“)", "url": "https://asia.nikkei.com/", "tag": "h4", "root": "https://asia.nikkei.com" }, 
    { "name": "Le Monde (ä¸–ç•Œå ±)", "url": "https://www.lemonde.fr/en/", "tag": "h3", "root": "" },
    { "name": "Der Spiegel (æ˜é¡å‘¨åˆŠ)", "url": "https://www.spiegel.de/international/", "tag": "h3", "root": "" },
    { "name": "Deutsche Welle (å¾·åœ‹ä¹‹è²)", "url": "https://www.dw.com/en/top-stories/s-9097", "tag": "h3", "root": "https://www.dw.com" },
    { "name": "El PaÃ­s (åœ‹å®¶å ±)", "url": "https://english.elpais.com/", "tag": "h2", "root": "https://english.elpais.com" },
    { "name": "Xinhua (æ–°è¯ç¤¾)", "url": "https://english.news.cn/", "tag": "span", "root": "" },
    { "name": "SCMP (å—è¯æ—©å ±)", "url": "https://www.scmp.com/news/world", "tag": "h2", "root": "https://www.scmp.com" }
]

translator = GoogleTranslator(source='auto', target='zh-TW')

headers = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
    "Accept-Language": "en-US,en;q=0.9",
    "Referer": "https://www.google.com/"
}

# å…¨åŸŸè®Šæ•¸ï¼šç”¨ä¾†ç´¯ç©æ‰€æœ‰è¦å¯„å‡ºçš„å…§å®¹
full_content = ""

def log_and_save(text):
    """ åŒæ™‚æ‰“å°åˆ°è¢å¹•ã€å¯«å…¥æª”æ¡ˆã€ä¸¦å­˜å…¥ Email å…§å®¹ç·©è¡å€ """
    global full_content
    print(text)
    full_content += text + "\n"
    with open("news_report.txt", "a", encoding="utf-8") as file:
        file.write(text + "\n")

# --- å¯„ä¿¡åŠŸèƒ½ ---
def send_email_report():
    email_user = os.getenv('EMAIL_USER')
    email_password = os.getenv('EMAIL_PASSWORD')

    if not email_user or not email_password:
        print("âš ï¸ æ‰¾ä¸åˆ° Email è¨­å®šï¼Œè·³éå¯„ä¿¡æ­¥é©Ÿã€‚")
        return

    msg = MIMEMultipart()
    msg['From'] = email_user
    msg['To'] = email_user  # å¯„çµ¦è‡ªå·±
    msg['Subject'] = f"ğŸ“° æ¯æ—¥æ–°èå¿«å ± ({datetime.now().strftime('%Y-%m-%d')})"

    # å°‡å…§å®¹è½‰ç‚º HTML æ ¼å¼ç¨å¾®ç¾åŒ–ä¸€ä¸‹
    html_content = f"""
    <html>
      <body>
        <h2>ğŸŒ ä½ çš„æ¯æ—¥é‡é»æ–°è</h2>
        <pre style="font-family: Arial; font-size: 14px;">{full_content}</pre>
        <hr>
        <p>Sent by Daily News Bot ğŸ¤–</p>
      </body>
    </html>
    """
    msg.attach(MIMEText(html_content, 'html'))

    try:
        # é€£ç·šåˆ° Gmail ä¼ºæœå™¨
        server = smtplib.SMTP_SSL('smtp.gmail.com', 465)
        server.login(email_user, email_password)
        server.send_message(msg)
        server.quit()
        print("\nğŸ“§ Email å¯„é€æˆåŠŸï¼è«‹æª¢æŸ¥æ”¶ä»¶åŒ£ã€‚")
    except Exception as e:
        print(f"\nâŒ Email å¯„é€å¤±æ•—: {e}")

# --- ä¸»ç¨‹å¼ ---
# æ¸…ç©ºèˆŠæª”
with open("news_report.txt", "w", encoding="utf-8") as file:
    file.write("")

log_and_save(f"=== æ¯æ—¥é‡é»æ–°èå½™æ•´ ===\næ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n")

# é–‹å§‹æŠ“å–
for source in news_sources:
    site_name = source["name"]
    url = source["url"]
    tag = source["tag"]
    root_url = source["root"]
    
    log_and_save(f"ğŸš€ {site_name}...")
    
    try:
        response = requests.get(url, headers=headers, timeout=15)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, "html.parser")
            items = []

            if site_name == "CNN":
                items = soup.find_all("span", class_="container__headline-text") or soup.find_all("span")
            elif site_name == "Xinhua (æ–°è¯ç¤¾)":
                items = soup.find_all("div", class_="tit") or soup.find_all("span")
            elif site_name == "Nikkei Asia (æ—¥ç¶“)":
                 items = soup.find_all("h4")
            else:
                items = soup.find_all(tag)
            
            count = 0
            seen = set()
            
            for item in items:
                if count >= 5: break
                
                link = item.find_parent("a") or item.find("a") if tag in ["h2","h3","h4","span","div"] else item
                
                txt = item.get_text(strip=True) or (link.get_text(strip=True) if link else "")
                
                if txt and len(txt) > 10 and txt not in seen:
                    seen.add(txt)
                    try:
                        zh_txt = translator.translate(txt)
                    except:
                        zh_txt = txt
                    
                    link_url = link.get("href") if link else ""
                    if link_url and not link_url.startswith("http"):
                        link_url = root_url + link_url
                    
                    log_and_save(f"   ğŸ“° {zh_txt}")
                    log_and_save(f"   ğŸ”— {link_url}\n")
                    count += 1
            
            if count == 0: log_and_save("   âš ï¸ æœªæŠ“åˆ°æ–°è")
        else:
            log_and_save(f"   âŒ é€£ç·šå¤±æ•—: {response.status_code}")
            
    except Exception as e:
        log_and_save(f"   âŒ éŒ¯èª¤: {e}")
    
    log_and_save("-" * 30)
    time.sleep(1)

# æœ€å¾Œå¯„å‡º Email
send_email_report()
print("ğŸ’¤ ä»»å‹™å…¨éƒ¨å®Œæˆï¼")
